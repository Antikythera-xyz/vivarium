<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>VIVARIUM</title>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <div class="banner">
      <div id="title">VIVARIUM</div>
    </div>
  </header>
  <main>
      <div id="vid">
        <iframe src="https://player.vimeo.com/video/806962726?h=8a84b6125f" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
      </div>
      <div id="act1" class="textSection">
        <div class="text">
          <h1>
            SIMULATING AI ENVIRONMENTS
          </h1>
          <p>
            If AI agents are to exist in the world, their cognitive processes must be integrated with a range of physical and immaterial sensory input.
          </p>
          <p>
            DeepMind trains interactive agents within 3D environments to understand human instructions and perform actions in open-ended settings.<a href="https://www.deepmind.com/blog/building-interactive-agents-in-video-game-worlds">¹</a> Through reinforcement learning, these agents learn complex behaviors such as physical manipulation, experimentation, and multi-agent coordination. Other private companies employ simulations to train AIs for autonomous driving, industrial robotics, and surgical operation.
          </p>
          <div class="imgRow wide spread side">
            <img src="img/deepmind1.png" />
            <img src="img/deepmind2.png" />
          </div>
          <p>
            These environments are Toy Worlds: simulations in which reality is abstracted into a bounded domain for training and testing AI agents. They offer domains that are controlled and safe, malleable and interoperable. Time is compressed within them to sped-up machine temporalities. Toy Worlds allow for quick iteration, broad proliferation, and streamlined data synthesis, in the pursuit of physicalized artificial intelligence.
          </p>
          <p>
            While some Toy Worlds are built exclusively for AIs, others contain both humans and AIs. Structured as games, they enable the study of human-AI interaction and broader human sociality. These games explore different configurations of AI and human agents, allowing negotiations that are prohibitively expensive or dangerous within the real world.
          </p>
          <div class="imgRow center">
            <img class="textWidth" src="img/matrix.png" />
          </div>
          <p>
            A Toy World with a single human and a single AI can allow both parties to physically and cognitively coordinate shared control. Worlds with many humans and a single AI can offer a top-down view of human sociality, while worlds with many AIs and a single human can reveal a bottom-up emergence of broad patterns from programmed behaviors. Humans can play as noise injections or executive control, lab rat or god. When these interactions are digitized within a Toy World at scale, robust and general physicalized AI becomes viable.
          </p>
        </div>
      </div>
      <div id="act2" class="textSection">
        <div class="text">
          <h1>
            A PLATFORM OF TOY WORLDS
          </h1>
          <div class="imgStickyBg">
            <img id="vivarium" src="img/vivarium.png" />
          </div>
          <div id="vivariumBlur">
            <p>
              Imagine a laboratory crossed with a gaming distribution platform: a Vivarium for Artificial Intelligence. Toy Worlds and AI agents on this platform can be “kitted” from an open asset library. Parts can be forked and merged to create new instances, allowing for longitudinal learning and interoperable data.
            </p>
            <div class="imgRow slightWide center">
              <img src="img/assets.png" />
            </div>
            <p>
              The developers of Toy Worlds on Vivarium range from hobbyists to game studios, governments to institutions. Their motivations range from research to entertainment. Authorship of these components is transparent and traceable, allowing lineages of AI and Toy Worlds to emerge from cycles of iterative development.
            </p>
            <div class="imgRow center">
              <img class="textWidth" src="img/compass.png" />
            </div>
            <p>
              Mass participation proliferating interactive training data is necessary to get to real-world embodied AI. Game participation structures span paid-to-play, incentivizing players through microwork, to pay-to-play, offering intrinsically motivating exploration and fun. Vivarium introduces a paradigm beyond productivity-based human-AI interaction, blurring the line between data generation and play.
            </p>
            <p>
              Beyond participation at scale, the range of worlds on Vivarium also allows for targeted specificity. Each Toy World projects a partial depiction of reality, but the platform as a whole accumulates both universal knowledge from broad systems and particular knowledge from embedded interactions. The agglomeration of Toy Worlds, each with varying degrees of human-AI entanglement, allows Vivarium to contain myriad possibilities of technical and sociopolitical configuration.
            </p>
          </div>
        </div>
      </div>
      <div id="game1" class="textSection">
        <div class="text">
          <h1>
            SENSORIMOTOR SIMULATION
          </h1>
          <div class="imgStickyBg singleType">
            <img id="sensorimotor" src="img/sensorimotor.png" />
          </div>
          <p id="sensorimotorBlur">
            Sensorimotor simulations contain hyper-accurate physics engines, filled with AIs only. Developers train single or multiple AIs to complete tasks and learn embodied intelligence including physical movement, dexterity, and trail blazing.
          </p>
          <div class="gameText">
          <h2>
            Junkyard Eden
          </h2>
          <div class="imgRow slightWide center">
            <img src="img/junkyardeden.png" />
          </div>
            <p>
              AI agents, both as individuals and groups, learn to sustain themselves by collecting materials within a procedurally generated open world. Emergent behaviors include designing and building tools, collecting resources for self-maintenance, and adapting to a changing environment.
            </p>
            <p>
              Created by human players, the agent’s goal is to complete a playthrough as fast as possible. While their bodies may be humanoid or animal-like, most agents are composed of customizable parts that allow for unexpected types of mobility in the world.
            </p>
            <p>
              AIs are trained in embodied cognition, learning sensorimotor skills including: movement, dexterity, and pathfinding. Real physics are prioritized above all else, to standardize learned motor ability. Embodied intelligence learned through gameplay transfers to real-world applications, while emergent types of mobility inspire new robotic forms.
            </p>
          </div>
          <h3>Embodied Cognition</h3>
          <p>
            Embodied cognition refers to types of cognition in which the body plays a decisive role. Here, “body” can span two extremes: from “extra-neuronal material support for symbolic information processing” to a “multiple, integrated, environmentally embedded system, whose biological dynamics of self-organization are inseparable from processes of sense-making.”<a href="https://www.frontiersin.org/articles/10.3389/fbioe.2021.724023/full">²</a>
          </p>
          <p>
            Data capturing embodied cognition is not easily accessible or even digitized. Through its training corpus of the scraped internet, a large language model such as GPT-4 can learn that a bow is “bending the head or upper part of the body,” but cannot learn how to actually wield a physical body to execute the gesture.
          </p>
          <p>
            Artificializing such processes is necessary for the physicalization of AI, so it can make the leap from language-wielding to world-making. However, training embodied AI in the real world is expensive and poses both physical danger and escape risk. A Toy World with a hyperaccurate physics engine bypasses these issues, with the hope that knowledge accumulated from simulation can be transferred to the real.
          </p>
          <p>
            Known as the “sim2real gap,” this transfer is not a given.<a href="https://dspace.mit.edu/bitstream/handle/1721.1/138850/2021-04-Sim2Real_T-ASE.pdf?sequence=2&isAllowed=y">³</a> The simulation may either fall short of correctly modeling actual physics (friction, impact, and deformation is particularly difficult to model) or fail to capture the indeterminacies of the real (a grocery delivery drone getting attacked by a dog after training in a sim without one). Vivarium enables an unprecedented amount of sensorimotor data to be captured through diverse simulations, to address this gap and teach AI a more generalized physics.
          </p>
        </div>
      </div>
      <div id="game2" class="textSection">
        <div class="text">
          <h1>
            CENTAUR PLATFORMER
          </h1>
          <div class="imgStickyBg singleType">
            <img id="platformer" src="img/platformer.png" />
          </div>
          <p id="platformerBlur">
            In centaur platformers, a human and an AI agent are partnered together. To explore new coordination paradigms, the pairing must physically and mentally collaborate to pass levels.
          </p>
          <div class="gameText">
            <h2>
              CENTAUR<br />PARKOUR
            </h2>
            <div class="imgRow slightWide center">
              <img src="img/centaurparkour.png" />
            </div>
            <p>
              Each player has an AI counterpart, whose form changes between an exoskeleton suit which extends their body, and an externalized companion creature. Together they must learn to play sports in a post-apocalyptic world of floating islands, such as parkour under alien physics.
            </p>
            <p>
              Beyond extending the human player’s motor ability, the AI as exoskeleton is also capable of mediating between the human sensorium and the environment. It takes on cognitive processing on behalf of the human, filtering and augmenting sight, hearing, and touch. As a companion, the AI can take many forms: drone, dog, battering ram. Both parties learn to navigate remote collaboration. The player can plug into the AI’s sensorium, trading bodily safety for projected perspective.
            </p>
            <p>
              The dynamics of human-AI corporeal coupling is negotiated through play. Players wear a haptic motion capture suit to enter this gameworld, but eventually the interactive intelligence that both develop through their simulated partnership allows embodied human-AI coordination to exist in the real.
            </p>
          </div>
          <h3>Partnership Paradigms</h3>
          <p>
            Beyond motor skills, an embodied AI must learn to interact with humans in close proximity. Humans must also decide how they want to physically coexist with AI. Both parties can negotiate their chimeric coupling in Toy Worlds, which facilitate flexible iteration and maintain physical safety.
          </p>
          <p>
            “Shared control” refers to an emerging interaction paradigm where human and AI are tightly-coupled and share a single interface to collaboratively control a system. Domains include operating surgical instruments, semi-autonomous driving, and telemanipulating robots. A centaur is one possible shared control configuration: the human provides the executive control as the AI provides stabilization, precision, or guidance. The centaur is capable of more than the sum of its parts as cognitive and physical load is distributed according to each party’s unique capability.
          </p>
          <p>
            There are alternate human-AI configurations beyond centaurs that remain unexplored, such as those that grant the AI executive function or are fully non-hierarchical and symbiotic. While allowing AI to set goals is a concern within safety research, Toy Worlds offer a low risk space to prototype such arrangements. On Vivarium, centaur platformers allow players to negotiate coexistence with embodied AI for themselves.
          </p>
        </div>
      </div>
      <div id="game3" class="textSection">
        <div class="text">
          <h1>
            MMARPG
          </h1>
          <div class="imgStickyBg singleType">
            <img id="mmarpg" src="img/mmarpg.png" />
          </div>
          <p id="mmarpgBlur">
            Massively multi-agent role-playing games are filled with many humans and AIs, allowing large-scale, distributed simulations of social, economic, and political configurations.
          </p>
          <div class="gameText">
          <h2>
            ASSEMBLY
          </h2>
          <div class="imgRow slightWide center">
            <img src="img/assembly.png" />
          </div>
            <p>
              In Assembly, human players engage in a cooperative clan-based social simulation where they must learn to thrive together on a planet of fungi. Players must collaborate, barter, and forge relationships—exploring alternative social structures. They can express themselves through chat and programmable, nonverbal gestures. New players spawn in a random polity, but have the freedom of exiting and remaking polities of their own.
            </p>
            <p>
              An AI manager overlooks the planet’s inhabitants, arbitrating resource distribution within the world. It has two tasks: modify the conditions to test robustness of different player polities, and observe broad patterns of human social dynamics and coexisting structures.
            </p>
            <p>
              This large-scale, distributed simulation of alternate sociopolitical structures stress-tests new possibilities of human organization in the context of ecological uncertainty, while allowing the AI to learn a topology of human social interaction.
            </div>
          <h3>Social A/B Testing</h3>
          <p>
            Massively multi-agent role-playing games are filled with many humans and AIs, allowing large-scale, distributed simulations of social, economic, and political configurations. Grid cells and place cells in the animal brain create a “cognitive map” of space, but are also found to spatially map out concepts such as social hierarchy.<a href="https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/">⁷</a> An AI could also learn sociality spatially through observing human interactions.
          </p>
          <p>
            It takes time for a human researcher to study the causal processes that construct social reality in a highly parameterized simulation. Digitizing these interactions within a Toy World allows AI to quickly interpret social behavior at interrelated scales and trace how macro patterns emerge from micro interactions.</p>
          <p>
            In these social simulations, AI does not optimize for any particular behavior. Rather, it observes the emergent structures and individual responses that arise from set conditions. At the same time, the social A/B testing within MMARPGs has the potential to create real harm: fascism induced by the AI’s resource distribution in simulation is nevertheless experienced by players.
          </p>
          <p>
            Outside of the Toy World, various social configurations are analogous to those within simulations. The AI can learn processes for phasing between existing social realities and more desirable ones. Ultimately, the scope of AI’s mediation in human sociality at different scales in the real world should remain under interrogation, even as they are rehearsed in expansive MMARPGs.
          </p>
        </div>
      </div>
      <div id="act3" class="textSection">
        <div class="text">
          <h1>
            BEYOND WORLDING
          </h1>
          <p>
            As an interoperable platform of Toy Worlds, Vivarium offers AI a multitude of experiences from which to reproductively recombine forms, objectives, and skills. AI can practice autonomy in a low risk environment. Human-AI pairings can search for novel symbiotic relationships. AI can learn the structure of human social, economic, and political realities from observation.
          </p>
          <p>
            Toy Worlds tie the affordances of embodied AI to the limits of human cognition while prototyping instances in which AI can broaden its own cognition. Within these kitbashed sandboxes, human and AI mutually expand their capacity for understanding, relating, and cooperating through play. The seed bank of worlds on Vivarium allows dynamic new forms of embodied intelligence to be playtested en masse.
          </p>
        </div>
      </div>
  </main>
</body>
<script src="js/scroll.js"></script>
</html>
